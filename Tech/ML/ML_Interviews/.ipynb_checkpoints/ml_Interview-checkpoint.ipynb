{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #1 \n",
    "\n",
    "### Difference between Supervised and Unsupervised Learning ?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Supervised learning is when each example of dataset is labeled. For example, in classifying between a dog and cat, each training example will mention the label that whether it is a cat or a dog. \n",
    "### On the other hand, in Unsupervised learning each example has no such label. Clustering is a technique which is most widely used in unsupervised learning tasks to group data points which have the same attributes. \n",
    "\n",
    "### A detailed list of algorithms within Supervised and Unsupervised domains can be found as following:\n",
    "\n",
    "<img src=\"supVSunsup.PNG\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #2\n",
    "\n",
    "### What is Semi-supervised Learning?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### In this type of learning, dataset consists of a small amount of labeled data while rest of dataset is un-labeled. It is challenging to label large data sets as it requires human supervision. Semi-supervised helps in this aspect because it can learn from few labeled examples and then label rest of the un-labeled examples. \n",
    "\n",
    "### Different methods are used in this type of learning such as Generative, Low-density separation, Graph-based, Heuristic approaches etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #3\n",
    "\n",
    "### What is Reinforcement Learning?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### It is a type of learning which involves taking actions within an environment and getting a reward plus environment state as a result of each action. With each feedback received, the model updates itself to maximize rewards in future actions. \n",
    "\n",
    "<img src=\"RL.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #4\n",
    "\n",
    "### What is Deep Learning?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### It is a sub-field of machine learning which is concerned with algorithms and models inspired by artificial neural networks.\n",
    "\n",
    "### Example - Convolutional Neural Networks, Recurrent Neural Networks etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #5\n",
    "\n",
    "### What is Self-Supervised Learning?\n",
    "\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Self-supervised is a sub-set of unsupervised learning. It can learn from itself by learning intrinsic properties. It can generate output labels from input data if given a relation between parts of the object.\n",
    "\n",
    "### Example, can be of predicting missing word if given context of sentence. Another example can be of an image which modified itself as input and model has to predict what changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #6\n",
    "\n",
    "### What is difference between Generative Models and Discriminative Models?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Generative models learn the actual distribution of each class. It uses joint probability distribution to achieve this. Example algorithms are of Naive Bayes, Bayesian networks, Hidden Markov Models etc.\n",
    "\n",
    "### Discriminative models learn the decision boundary between classes. It uses conditional probability distribution to achieve this. Example algorithms are of Logistic regression, Scalar Vector Machine, Neural Networks etc. \n",
    "\n",
    "<img src=\"genVSdisc.PNG\" alt=\"Drawing\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #7\n",
    "\n",
    "### What is the difference between bias and variance ?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Bias is the difference between prediction of our model and the actual values, which can be summarized as the inability of our model to capture the true relationship. High bias usually results in underfitting as our model is oversimplified in this case. \n",
    "\n",
    "### Variance is the variability of model prediction for a given data which tells us the spread of data. High variance usually results in overfitting as our model does not generalize enough.\n",
    "\n",
    "### Bias/Variance tradeoff is an important concept here as we want to find optimal balance so that our model don't overfit or underfit.\n",
    "\n",
    "<img src=\"biasVSvariance.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #8\n",
    "\n",
    "### What is Linear Regression?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Linear regression is a linear approach to model a relationship between dependent and independent variables by fitting a line between them. \n",
    "\n",
    "### Mathematically, it can be represented with an equation as follow:\n",
    "\n",
    "###                                                                       y = wx + b ; where b is bias, x is input vector, y is output vector and w is weight\n",
    "\n",
    "### There are different methods used in linear regression such as least square regression, LASSO and least absolute deviations. Algorithms used to complete these methods can be Analytical Solution, Gradient Descent and Conjugate Gradient.\n",
    "\n",
    "### This image shows a straight line using linear regression that fits between different data points. \n",
    "\n",
    "\n",
    "<img src=\"linearRegression.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #9\n",
    "\n",
    "### What is Logistic Regression?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Logistic Regression is a classification method for binary classification. It classifies using a linear classification that is to fit a curve between two different classes. Remember that logistic regression is not a regression method. It only tells us whether an input belongs to one class or another. \n",
    "\n",
    "### Mathematically, it can be represented as follows:\n",
    "\n",
    "### y = wx ; w = [w,b] \n",
    "\n",
    "### if y = +1 then wx > 0\n",
    "### if y = -1 then wx < 0\n",
    "\n",
    "### There are different algorithms to calculate logistic regression method such as Gradient Descent, Accelerated Gradient Descent and Stochastic Gradient Descent. \n",
    "\n",
    "### Following image shows how logistic regression differentiates between two different classes.\n",
    "\n",
    "<img src=\"linearVSlogistic.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #10\n",
    "\n",
    "### Difference between Logistic and Linear Regression?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### The main difference is that Linear Regression is a regression algorithm while Logistic Regression is a classification algorithm. The output of Linear R* is continuous while Logistic R* output is discrete. \n",
    "\n",
    "### Another important difference is that Linear R* assumes that distribution of dependent variables is normal while Logistic R* assumes that it is binomial. \n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://medium.com/@dhiraj8899/top-5-difference-between-linear-regression-and-logistic-regression-893f6470d7e0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #11\n",
    "\n",
    "### What is Sigmoid function?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Sigmoid function is a mathematical function which is used as an activation function to produce probabilities from predictions. It maps any real value into another values between 0 and 1. \n",
    "\n",
    "### Its equation is as follows:\n",
    "\n",
    "<img src=\"sigmoidEq.PNG\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "### where z is input to function i-e prediction = wx+b, e is base of natural log\n",
    "\n",
    "### It is \"S\" shaped same as that of logistic regression shown in answer of Question #9.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #12\n",
    "\n",
    "### What is SVM(Support Vector Machine)?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Support Vector Machine is a supervised machine learning algorithm which is used to classification tasks. It uses a hyperplane to differentiate between different classes. Best hyperplane is the one that maximizes the margin from each class.\n",
    "\n",
    "### For non-linear data, SVM uses kernel tricks to classify classes. These kernels include polynomial kernel, sigmoid kernel, gaussian kernel etc.\n",
    "\n",
    "### Following is an image of SVM.\n",
    "\n",
    "<img src=\"svm.JPG\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #13\n",
    "\n",
    "### What are one vs rest (OVR) classifiers?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### It is a type of classification which is used for multi-class classification by considering one class as positive while the rest of the classes as negative. \n",
    "\n",
    "### One of the issues it faces is that they see unbalanced distributions because typically the number of positive samples are less than negative samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #14\n",
    "\n",
    "### Define different evaluation metrics\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Different evaluation metrics are used for tasks such as classification and regression. I will name a few of them as follows:\n",
    "\n",
    "### Regression Evaluation Metrics - RMSE(root mean square error), MAE(mean absolute error)\n",
    "\n",
    "### Classification Evaluation Metrics - Accuracy, Precision, Recall, F-1 Score, Log Loss, Categorical Crossentropy, AUC/ROC\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226\n",
    "\n",
    "https://medium.com/usf-msds/choosing-the-right-metric-for-machine-learning-models-part-1-a99d7d7414e4\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between Sensitivity and Specificity? Relationship with ROC?\n",
    "\n",
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #15\n",
    "\n",
    "### What is the different between multi-class and multi-label classification?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Multi-class classification is a type in which model differentiates between labels that are are singular in nature i-e it can be X or Y or Z but it can not be two or more classes in one label.\n",
    "\n",
    "### Multi-label classification is a type in which model differentiates between labels that can have more than one class i-e it can be X & Y or X & Y & Z or X only.\n",
    "\n",
    "### The following image shows a clear picture.\n",
    "\n",
    "<img src=\"multilabelvsclass.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #16\n",
    "\n",
    "### What is a Confusion matrix?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Confusion matrix is a matrix that is used to explain the performance of a classification algorithm for which labels are known(supervised learning). We plot predicted labels vs actual labels to get a matrix and observe how the model is confusing each of the classes.\n",
    "\n",
    "### Following is an example of confusion matrix shown using scikit-learn\n",
    "\n",
    "<img src=\"conf_matrix.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #17\n",
    "\n",
    "### Give some examples of high bias algorithms?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Most of the algorithms which have high bias are related with linear in nature. As these algorithms consider there is a linear relationship between variables. Examples include Linear Regression, Logistic Regression and Linear Discriminant Analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #18\n",
    "\n",
    "### Give some examples of high variance algorithms?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Algorithms which have high variance are usually related with non-linear data. As these algorithms, focus too much on the training data which results in not generalizing well. Examples include Decision Trees, K-NN(nearest neighbors), SVM(support vector machines).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #19\n",
    "\n",
    "### What is Prediction Bias and what are its causes?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Prediction bias is the measure of how far is average of predictions from the average of labels in data set. It can be shown using following equation\n",
    "\n",
    "### prediction bias = average of predictions - average of labels in data set\n",
    "\n",
    "### Following can be the causes of prediction bias:\n",
    "\n",
    "### 1. Noisy data set\n",
    "\n",
    "### 2. Incomplete feature set\n",
    "\n",
    "### 3. Buggy pipeline\n",
    "\n",
    "### 4. Biased training sample\n",
    "\n",
    "### 5. Overly strong regularizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #20\n",
    "\n",
    "### What is Gradient Descent algorithm? \n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Gradient descent algorithm is an optimization algorithm that is used to minimize some function by moving towards the direction given by gradient. The idea is to calculate gradients and then move towards negative direction so that loss can be minimized. \n",
    "\n",
    "### It consists of following steps:\n",
    "\n",
    "### 1. Initialize weights, bias, learning rate \n",
    "\n",
    "### 2. With each step, calculated partial derivatives of model and update weights using those partial derivatives plus learning rate.\n",
    "\n",
    "### 3. Stop, when there is no significant change in error i-e cost function converges.\n",
    "\n",
    "### Following image shows the process\n",
    "\n",
    "\n",
    "<img src=\"gradientdescent.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #21\n",
    "\n",
    "### What is Stochastic Gradient Descent?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Stochastic Gradient Descent is a variation of GD in which instead of using all data we take random samples from the data and keep on updating weights while decreasing learning rate with each step.\n",
    "\n",
    "### It consists of following steps:\n",
    "\n",
    "### 1. Initialize weights, bias, learning rate \n",
    "\n",
    "### 2. With each step take random sample from data, calculated partial derivatives of model and update weights using those partial derivatives plus learning rate.\n",
    "\n",
    "### ..............  2(a). Update weights and decrease learning rate\n",
    "\n",
    "### ..............  2(b). Continue until epochs are fininshed. \n",
    "\n",
    "### 3. Return final weights.\n",
    "\n",
    "\n",
    "### The following image shows difference between SGD and GD\n",
    "\n",
    "<img src=\"stochastic.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #22\n",
    "\n",
    "### What is mini-batch gradient descent?\n",
    "\n",
    "### Anwer:\n",
    "\n",
    "### Mini-batch gradient descent is same as stochastic gradient descent, the only difference is that instead of taking only one sample as in SGD we take a mini-batch from data and use that to update weights.\n",
    "\n",
    "### Following image shows a clear distinction between each\n",
    "\n",
    "<img src=\"minibatch.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quesiton #23\n",
    "\n",
    "### What is the difference between epochs and iterations?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Epochs is the number of times learning algorithm has gone over the data. While iteration is the number of times the algorithm has gone over all the data. Epochs is used with SGD(stochastic gradient descent) which takes random samples from data, while iterations is used for algorithms which process all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #24\n",
    "\n",
    "### What are Decision Trees?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Decision Trees are learning algorithms which uses information gain to select attributes and go from observations about an item to item's target value in a tree like structure. \n",
    "\n",
    "### They can be used for both classificaiton and regression tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #25 \n",
    "\n",
    "### What are Random Forests?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Random Forest is an ensemble learning method which consists of multitude of decision trees. They can also be used for both classification and regression.\n",
    "\n",
    "### Its algorithm is same as that of decision trees plus it uses bagging and during candidate split it selects a random subset of the features.\n",
    "\n",
    "<img src=\"RF.JPG\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #26\n",
    "\n",
    "### What is the process of splitting and pruning in decision trees?\n",
    "\n",
    "### Anwer:\n",
    "\n",
    "### Splitting is a technique used by decision trees to split data into subsets based on some metric. It helps to reach a point where each subset is homogenous and there is no more room to split. \n",
    "\n",
    "### Pruning is also a technique used to reduce time and reach a decision earlier. It is done by removing leaves and shortening branches. \n",
    "\n",
    "### The following example shows this in detail\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"pruningtree.PNG\" alt=\"Drawing\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #27\n",
    "\n",
    "### What is Entropy and Information Gain? Where these are used ?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Entropy is the randomness of data being processed. The higher the entropy, the harder is it to draw any conclusions from that data. \n",
    "\n",
    "### Entropy of random variable Y is as follows:\n",
    "\n",
    "<img src=\"entropy.PNG\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "### Information gain, on the other hand is about the decrease in entropy after splitting. Its equation is as follows:\n",
    "\n",
    "<img src=\"informationgain.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "### Both of these are used in constructing decision trees as we have to find attributes that have the highest information gains i-e most homogenous branches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #28\n",
    "\n",
    "### Algorithm for Entropy?\n",
    "\n",
    "### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quesiton #29\n",
    "\n",
    "### What is Gini Index?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Gini Index is used for splitting in decision trees. It is calculated by subtracting squared probability of each class by one. \n",
    "\n",
    "### It formula is as follows:\n",
    "\n",
    "<img src=\"gini_index.PNG\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "### A perfectly classified gini index would be zero. It usually favors larger partitions and we want a variable split that has a low gini index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #30\n",
    "\n",
    "### What is difference between Probability and Likelihood?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Probabilities are attached to results while likelihood are attached to hypothesis. Probabilities can be mutually exclusive and exhaustive while likelihood is neither. Probabilities quantifies anticipation of outcomes while likelihood quantifies trust in model.\n",
    "\n",
    "### Example can be if somebody challenges us to a 'profitable gambling game'. Then, probabilities will serve us to compute things like the expected profile of your gains and loses (mean, mode, median, variance, information ratio, value at risk, gamblers ruin, and so on). In contrast, likelihood will serve us to quantify whether we trust those probabilities in the first place; or whether we 'smell a rat'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quesiton #31\n",
    "\n",
    "### What is KL-Divergence?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Kullback leibler divergence is a measure which shows how one probability distribution is different from another probability distribution.\n",
    "\n",
    "### Its equation is as follows:\n",
    "\n",
    "<img src=\"klDivergence.PNG\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "### These equations are for discrete and continuous cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #32\n",
    "\n",
    "### What is Cross-Entropy?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Cross Entropy is a measure that is also used to know difference between two probability distributions. It is different from KL-Divergence as it deals with calculating the total entropy between two distributions while KL-Divergence calculates relative entropy between distributions.\n",
    "\n",
    "### Its equation is as follows:\n",
    "\n",
    "<img src=\"crossentropy.PNG\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "### Following equation shows a relationship between cross entropy and KL divergence.\n",
    "\n",
    "<img src=\"klVScross.PNG\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "### Further Reading \n",
    "\n",
    "https://tdhopper.com/blog/cross-entropy-and-kl-divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #33\n",
    "\n",
    "### What is AUC/ROC curve?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### AUC-ROC(receiver operating characterisitc) curve is a performance measurement for classification problems and it helps in telling that how much model is capable of distinguishing between different classes. The more area under curve means better the model in predicting multiple classes. \n",
    "\n",
    "<img src=\"roc.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "### Sensitivty = TPR(True Positive Rate)= Recall = TP/(TP+FN)\n",
    "\n",
    "### Specificity = FPR(False Positive Rate)= FP/(TN+FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #34\n",
    "\n",
    "### Differentiate between Precision and Recall?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Precision is a measure which is fraction of relevant instance among the retrieved instances.\n",
    "\n",
    "### Recall is a measure which is a fraction of total number of relevant instances that were actually retrieved.\n",
    "\n",
    "### Following equation shows each of them \n",
    "\n",
    "\n",
    "<img src=\"recallVSprecision.PNG\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #35\n",
    "\n",
    "### Differentiate between Type I and Type II error?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Type I error is False Positive which happens when model incorrectly predicts the positive class e.g was cat but predicted a dog\n",
    "\n",
    "### Type II error is False Negative which happens when model incorrectly predicts the negative class e.g was not cat but predicted cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #36\n",
    "\n",
    "### What is F-1 Score?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### F-1 score is a measure which is the harmonic mean of precision and recall. It is also known as Dice Similarity Coefficient. Few scientists have also criticed its widely usage as it give equal importance to both precision and recall.\n",
    "\n",
    "### Following is its equation:\n",
    "\n",
    "\n",
    "<img src=\"f1Score.PNG\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #37\n",
    "\n",
    "### What are Outliers? Removal stratergies?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Outliers is a data point which deviates from the other data points. \n",
    "\n",
    "<img src=\"outlier.JPEG\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "### They can be removed using following ways:\n",
    "\n",
    "### 1. Using Inter Quartile Range \n",
    "### 2. Use Z-score removal i-e removal all data points away from mean\n",
    "### 3. A combination of Z-score and Inter Quartile Range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #38\n",
    "\n",
    "### What is Regularizaiton?\n",
    "\n",
    "### Anwer:\n",
    "\n",
    "### Regularization is a method that is used to reduce overfitting and discourages a model to be more complex. It shrinks the coefficient estimates towards zero. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #39\n",
    "\n",
    "### Differentiate between L1 and L2 regularizaiton?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### L1 regularization is also known as Lasso(least absolutre shrinkage and selection operator) Regularization. It adds an absolute magnitude of coefficient as penalty to the loss function.\n",
    "\n",
    "### L2 regularization is known as Ridge Regression. It adds a square magnitude of coefficient to loss function.\n",
    "\n",
    "<img src=\"L1VSL2.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "### L1 creates sparse outputs while L2 does non-sparse outputs. Another difference is that L1 has built in feature selection, on the other hand L1 does not have any feature selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #40\n",
    "\n",
    "### What is Sampling? Describe its different techniques?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Sampling is a technique that is used to apply calculations only on sample take from total population instead of investigating the whole dataset. This sample is a subset of total data which helps to identify patterns.\n",
    "\n",
    "<img src=\"sampling.PNG\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Different techniques are as follows:\n",
    "\n",
    "### 1. Random Sampling\n",
    "### 2. Stratified Sampling\n",
    "### 3. Cluster Sampling\n",
    "### 4. Multistage Sampling\n",
    "### 5. Symentaic Sampling\n",
    "\n",
    "### Further Reading \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2019/09/data-scientists-guide-8-types-of-sampling-techniques/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #41\n",
    "\n",
    "### What is difference between Undersampling and Oversampling?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Undersampling is about selecting sample from majority class and then deleting them. It is usually done randomly to balance the dataset. \n",
    "\n",
    "### Oversampling is about copies of some of the minority class to training data. It is also done randomly for balancing dataset. \n",
    "\n",
    "<img src=\"overVSunder.PNG\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "### Further Reading \n",
    "\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #42\n",
    "\n",
    "### What is Imbalanced Data? How would you resolve it?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### An imbalanced dataset is the one which does not have same distribution of each class within it. \n",
    "\n",
    "### For example, if cat has 500K samples in data and dog has 5K samples then this is not balanced. \n",
    "\n",
    "### Following techniques can be used to overcome this imbalance\n",
    "\n",
    "### 1. OverSampling\n",
    "\n",
    "### 2. UnderSampling\n",
    "\n",
    "### 3. SMOTE(synthetic minority oversampling)\n",
    "\n",
    "### 4. Adding in more data\n",
    "\n",
    "### 5. Algorithmic Ensembling techniques\n",
    "\n",
    "### Further Reading \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #43\n",
    "\n",
    "### What is ARIMA? How would you define weighted moving averages?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### ARIMA is a regressive and moving average model. It stands for Auto Regressive Integrated Moving Averages. It is a technique which is used to do regression analysis with moving averages to fit time series analysis and trend analysis with acceptable scores.\n",
    "\n",
    "### Weighted moving average is a method used to keep values which are repeated overtime as high priority. It has weighted multiple used with the moving average.\n",
    "\n",
    "### Further Reading \n",
    "\n",
    "https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/#:~:text=So%20what%20exactly%20is%20an,used%20to%20forecast%20future%20values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #44\n",
    "\n",
    "### What is Bagging and Boosting?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Bagging is a technique used to decrease variance by generating more data from original dataset for training. \n",
    "\n",
    "### For example, Random Forests do random sampling using bagging.\n",
    "\n",
    "### Boosting is technique which is used to adjust weights based on the previous classification.\n",
    "\n",
    "### For example, AdaBoost(it combines many weak classifiers to make one strong classifier), XGBoost(gradient boosting)\n",
    "\n",
    "<img src=\"baggVSboost.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "### Further Reading  \n",
    "\n",
    "https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/#:~:text=Bagging%20is%20a%20way%20to,based%20on%20the%20last%20classification.\n",
    "\n",
    "https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #45\n",
    "\n",
    "### What is IQR? How it can be used for outliers?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### IQR is interquartile range. It specifies range between third and first quartile.\n",
    "\n",
    "### Q1 - 0-25% , Q2 - 25-50%, Q3 - 50-75%, Q4 75-100%\n",
    "\n",
    "### IQR = Q3 - Q1\n",
    "\n",
    "### Outliers are detected with a rule that it is greater than 1.5 * IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #46\n",
    "\n",
    "### How can we resolve overfitting and underfitting?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Uderfitting can be resolved using following techniques\n",
    "\n",
    "### 1. Increasing complexity of model\n",
    "\n",
    "### 2. Inreasing training time\n",
    "\n",
    "### 3. Decreasing learning rule\n",
    "\n",
    "\n",
    "\n",
    "### Overfitting can be resolved using following methods\n",
    "\n",
    "### 1. Cross Validation\n",
    "\n",
    "### 2. Early Stopping\n",
    "\n",
    "### 3. Ensembling\n",
    "\n",
    "### 4. Removing Features\n",
    "\n",
    "### 5. Increasing learing rate\n",
    "\n",
    "### 6. Adding in more data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #47\n",
    "\n",
    "### What is neuron and perceptron?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### A perceptron is an artificial copy of neuron of our brain. It takes in a vector of inputs, performs some transformation on it and then outputs a single scalar value.\n",
    "\n",
    "<img src=\"perceptron.PNG\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://towardsdatascience.com/perceptron-the-artificial-neuron-4d8c70d5cc8d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #48\n",
    "\n",
    "### Differentiate between input, hidden and output layers?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### All of these layers are a part of artificial neural network architecture.\n",
    "\n",
    "### Input layer is the initial input to neural network. It is usually a number of features.\n",
    "\n",
    "### Hidden layer is in between input and output layer. It applies weights to inputs coming from input layer then passses them through some activation function. There can be multiple hidden layers in a neural network.\n",
    "\n",
    "### Output layer is the final layer which is used to produce outcomes. It get values from hidden layer and then applies some function depending on the application. Mostly in classification tasks Sigmoid and Softmax functions are used in output layer.\n",
    "\n",
    "### Here is an abstract view of each layer\n",
    "\n",
    "<img src=\"neuralN.JFIF\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #49\n",
    "\n",
    "### What is an activation funciton?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Activating funtion is a function that is used to transform input values to a range of values. Input can be a vector which is then scaled to values.\n",
    "\n",
    "### There are different activation functions, few are as follows:\n",
    "\n",
    "### 1. Sigmoid and Softmax function - creates non-negative values whose sum is always equal to one\n",
    "\n",
    "### 2. Tanh function - transforms to range between -1 and 1\n",
    "\n",
    "### 3. Relu function - transform to non-negative values ranging from 0 to max\n",
    "\n",
    "### 4. Leaky Relu function - is a variation of Relu function which resolves dying Relu problem\n",
    "\n",
    "### **Note - all of these are non-linear activation functions.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/\n",
    "\n",
    "https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #50\n",
    "\n",
    "### What is Forward propagation in neural networks?\n",
    "\n",
    "### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quesiton #51\n",
    "\n",
    "### What is Backward propagation in neural networks?\n",
    "\n",
    "### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #52\n",
    "\n",
    "### What is correlation and covariance?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Correlation is the measure of how change in one variables results in a change in another variables. It gives both direction and magnitude of the linear relationship.\n",
    "\n",
    "### Covariance on the other hand, is about how two variables vary together. It gives the direction of the linear relationship.\n",
    "\n",
    "### Both of these measure linear relationship between variables. \n",
    "\n",
    "<img src=\"covrianceVScorrelation.PNG\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://towardsdatascience.com/let-us-understand-the-correlation-matrix-and-covariance-matrix-d42e6b643c22#:~:text=In%20simple%20words%2C%20both%20the,linear%20relationship%20between%20two%20variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #53\n",
    "\n",
    "### What is Dimensionality Reduction? Why do we use it? Types?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Dimensionality reduction is technique that is used to reduce number of random variables under consideration. It is achieved by by obtaining a set of principal variables. \n",
    "\n",
    "### We do it mainly to tackle large amounts of data, longer training time and avoiding model overfitting.\n",
    "\n",
    "<img src=\"dimReduction.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "### Types of Dimensionality Reduction are as follows:\n",
    "\n",
    "### 1. Feature Selection\n",
    "\n",
    "### 2. Feature Projection (from higher to lower dimensions)\n",
    "\n",
    "### 3. Principal Component Analysis - linear\n",
    "\n",
    "### 4. Kernel PCA - nonlinear \n",
    "\n",
    "### 5. Linear Discriminant Analysis\n",
    "\n",
    "### 6. Generalized Discriminant Analysis\n",
    "\n",
    "### 7. t-SNE (distributed stochastic neighbor embedding) - for visualizations\n",
    "\n",
    "### 8. U-Map (uniform manifold approximation and projection)\n",
    "\n",
    "### 9. Autoencoders \n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/\n",
    "\n",
    "https://medium.com/@snehasathishdeva/introduction-to-dimensionality-reduction-2970a7d2a918\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #54\n",
    "\n",
    "### What is Principal Component Analysis?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Principal Component Analysis is a linear dimensionality reduction technique. It performs a linear mapping of data to lower dimensions in such a way that variance of data in this low dimension is maximized. \n",
    "\n",
    "### It uses singular value decomposition to find rotation matrix. We define a variable k which is used to select top variance directions as mentioned by k. \n",
    "\n",
    "<img src=\"pca.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #55\n",
    "\n",
    "### What is Maximum Likelihood Estimation?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Maximum Likelihood Estimation is a method that is used to determine values of parameters of a model. The parameter values are found in such a way that maximizes the likelihood of producing data same as that was observed.\n",
    "\n",
    "### Its goal is to find an optimal way to fit a distribution to data. \n",
    "\n",
    "### Further Reading \n",
    "\n",
    "https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #56\n",
    "\n",
    "### What is Bayes Theorem and Naive Bayes Algorithm?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Bayes theorem is a method that is used to describe probability of an event, based on prior knowledge of conditions that might be related to the event. \n",
    "\n",
    "### Its equation is as follows for events A and B:\n",
    "\n",
    "<img src=\"bayes.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "\n",
    "\n",
    "### Naive Bayes is an algorithm that uses bayes theorem as its base to find parameters of a probability distribution by maximizing a likelihood function. It is called Naive because it considers each features to be independent. \n",
    "\n",
    "<img src=\"naivebayes.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #57\n",
    "\n",
    "### What is Joint Probability, Conditional Probability, Marginal Probability, Continuous Probability Distribution?\n",
    "\n",
    "### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #58\n",
    "\n",
    "### What is Z-Score?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Z-Score is a metric that represents the number of standard deviations with which the value of a data point differ than the mean value of data observed.\n",
    "\n",
    "<img src=\"zscore.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #59\n",
    "\n",
    "### What is KNN?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### K-NN stands for K-Nearest Neighbors. It is a supervised learning method that is used for both classification and regression tasks. \n",
    "\n",
    "### In multi-class classificaiton, it performs better than softmax classifier if number of classes is huge. \n",
    "\n",
    "### It calculates similarities between different data points. These similarities can be cosine similarity, gaussian similarity etc.\n",
    "\n",
    "### Here is an abstract view\n",
    "\n",
    "<img src=\"knn.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://medium.com/datadriveninvestor/k-nearest-neighbors-knn-7b4bd0128da7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #60\n",
    "\n",
    "### What is K-Mean algorithm? Difference from KNN?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### K-means is an un-supervised clustering algorithm. It is used to cluster data points when there are no labels provided for dataset. \n",
    "\n",
    "### It uses mean to cluster data points together. k is for the number of clusters we want to make.\n",
    "\n",
    "<img src=\"k-means.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "### K-means is different from K-NN in following ways\n",
    "\n",
    "<img src=\"knnVSkmeans.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1\n",
    "\n",
    "https://becominghuman.ai/comprehending-k-means-and-knn-algorithms-c791be90883d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Question #61\n",
    "\n",
    "### What are Convolutional Neural Networks(CNN)?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Convolutional neural networks is a type of neural networks which uses convolution. They have convolutional layers, pooling layers and fully connected layers. \n",
    "\n",
    "### They are great in image recognition as convolutional layer helps in detecting edges, shapes and patterns. \n",
    "\n",
    "### They are also good in reducing complexity of the model i-e training becomes faster, reduces overfitting and need fewer samples. \n",
    "\n",
    "### They can have multiple convolutional, pooling and fully connected layers.\n",
    "\n",
    "### Following is an examples of a CNN\n",
    "\n",
    "<img src=\"cnn.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148\n",
    "\n",
    "https://medium.com/@purnasaigudikandula/a-beginner-intro-to-convolutional-neural-networks-684c5620c2ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #62\n",
    "\n",
    "### What are Recurrent Neural Networks(RNN)?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "### Recurrent Neural Network is a type of neural network which uses its internal state to process variable length of sequences. They have a lot of applications in language translation, image captioning, time series etc.\n",
    "\n",
    "### Following is an RNN image \n",
    "\n",
    "<img src=\"rnn.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n",
    "\n",
    "https://medium.com/mindorks/understanding-the-recurrent-neural-network-44d593f112a2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #63\n",
    "\n",
    "### What is meant by dropping neurons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #64\n",
    "\n",
    "### What is meant by flattening the layers?\n",
    "\n",
    "### Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #65\n",
    "\n",
    "### What are AutoEncoders?\n",
    "\n",
    "### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #66\n",
    "\n",
    "### What is Attention in Neural Networks?\n",
    "\n",
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #67\n",
    "\n",
    "### What are Transformers?\n",
    "\n",
    "### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #68\n",
    "\n",
    "### What is Image Captioning ?\n",
    "\n",
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #69\n",
    "\n",
    "### What is Text Summarization?\n",
    "\n",
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #70\n",
    "\n",
    "### What is Style Transfer?\n",
    "\n",
    "### Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #71\n",
    "\n",
    "### What is Image Segmentation and Pose Analysis?\n",
    "\n",
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #72\n",
    "\n",
    "### What are Semantic and Instance segmentations?\n",
    "\n",
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #73\n",
    "\n",
    "### What is Text Classification?\n",
    "\n",
    "### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #74 \n",
    "\n",
    "### What are GAN's?\n",
    "\n",
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "    \n",
    "#### Image - Question #1 - http://www.differencebetween.net/technology/differences-between-supervised-learning-and-unsupervised-learning/\n",
    "\n",
    "#### Image - Question #3 - https://www.researchgate.net/figure/Reinforcement-Learning-Agent-and-Environment_fig2_323867253\n",
    "\n",
    "#### Image - Question #6 - https://medium.com/@akankshamalhotra24/generative-classifiers-v-s-discriminative-classifiers-1045f499d8cc\n",
    "\n",
    "#### Image - Question #7 - https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229\n",
    "\n",
    "#### Image - Question #8 - https://en.wikipedia.org/wiki/Linear_regression\n",
    "\n",
    "#### Image - Question #9 - https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python\n",
    "\n",
    "#### Image - Question #12 - https://www.mitosistech.com/support-vector-machine/\n",
    "\n",
    "#### Image - Question #15 - https://suhitaghosh10.github.io/EurLexClassification/\n",
    "\n",
    "#### Image - Question #16 - https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "#### Image - Question #20 - https://blog.clairvoyantsoft.com/the-ascent-of-gradient-descent-23356390836f\n",
    "\n",
    "#### Image - Question #21 - https://www.researchgate.net/figure/Stochastic-gradient-descent-compared-with-gradient-descent_fig3_328106221\n",
    "\n",
    "#### Image - Question #22 - https://suniljangirblog.wordpress.com/2018/12/13/variants-of-gradient-descent/\n",
    "\n",
    "#### Image - Question #25 - https://www.kaggle.com/prashant111/random-forest-classifier-tutorial\n",
    "\n",
    "#### Image - Question #26 - https://towardsdatascience.com/decision-tree-algorithm-explained-83beb6e78ef4\n",
    "\n",
    "#### Image - Question #33 - https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/\n",
    "\n",
    "#### Image - Question #39 - https://medium.com/analytics-vidhya/regularization-in-machine-learning-and-deep-learning-f5fa06a3e58a\n",
    "\n",
    "#### Image - Question #40 - https://www.analyticsvidhya.com/blog/2019/09/data-scientists-guide-8-types-of-sampling-techniques/\n",
    "\n",
    "#### Image - Question #41 - https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb\n",
    "\n",
    "#### Image - Question #44 - https://medium.com/swlh/difference-between-bagging-and-boosting-f996253acd22\n",
    "\n",
    "#### Image - Question #48 - https://www.i2tutorials.com/introduction-to-neural-networks/\n",
    "\n",
    "#### Image - Question #53 - https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/\n",
    "\n",
    "#### Image - Quesiton #54 - https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c\n",
    "\n",
    "#### Image - Question #56 - https://www.saedsayad.com/naive_bayesian.htm\n",
    "\n",
    "#### Image - Question #59 - https://medium.com/@madanflies/k-nearest-neighbour-for-classification-on-breast-cancer-data-results-with-preprocessing-and-w-o-e21b0cc98a2f\n",
    "\n",
    "#### Image - Question #60 - https://www.quora.com/How-is-the-k-nearest-neighbor-algorithm-different-from-k-means-clustering\n",
    "\n",
    "#### Image - Question #62 - https://towardsdatascience.com/introduction-to-recurrent-neural-networks-rnn-with-dinosaurs-790e74e3e6f6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Important Interview Links\n",
    "\n",
    "1. https://www.springboard.com/blog/data-science-interview-questions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
